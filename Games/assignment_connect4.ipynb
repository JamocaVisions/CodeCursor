{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKvjKsiThOcl"
      },
      "source": [
        "# Adversarial Search: Playing Connect 4\n",
        "\n",
        "Student Name: [Add your name]\n",
        "\n",
        "I have used the following AI tools: [list tools]\n",
        "\n",
        "I understand that my submission needs to be my own work: [your initials]\n",
        "\n",
        "## Instructions\n",
        "\n",
        "Total Points: Undergraduates 100, graduate students 110\n",
        "\n",
        "Complete this notebook and submit it. The notebook needs to be a complete project report with your implementation, documentation including a short discussion of how your implementation works and your design choices, and experimental results (e.g., tables and charts with simulation results) with a short discussion of what they mean. Use the provided notebook cells and insert additional code and markdown cells as needed. Submit the completely rendered notebook as a HTML file.\n",
        "\n",
        "\n",
        "## Introduction\n",
        "\n",
        "You will implement different versions of agents that play Connect 4:\n",
        "\n",
        "> \"Connect 4 is a two-player connection board game, in which the players choose a color and then take turns dropping colored discs into a seven-column, six-row vertically suspended grid. The pieces fall straight down, occupying the lowest available space within the column. The objective of the game is to be the first to form a horizontal, vertical, or diagonal line of four of one's own discs.\" (see [Connect Four on Wikipedia](https://en.wikipedia.org/wiki/Connect_Four))\n",
        "\n",
        "Note that [Connect-4 has been solved](https://en.wikipedia.org/wiki/Connect_Four#Mathematical_solution)\n",
        "in 1988. A connect-4 solver with a discussion of how to solve different parts of the problem can be found here: https://connect4.gamesolver.org/en/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctU-mOKIhOcn"
      },
      "source": [
        "## Task 1: Defining the Search Problem [10 point]\n",
        "\n",
        "Define the components of the search problem:\n",
        "\n",
        "* Initial state\n",
        "* Actions\n",
        "* Transition model (result function)\n",
        "* Goal state (terminal state and utility)\n",
        "\n",
        "Describe each component and then implement it as a function that can be used by search algorithms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KdnTy-CKhOcn"
      },
      "outputs": [],
      "source": [
        "# Your code/answer goes here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RD1LL5XnhOco"
      },
      "source": [
        "How big is the state space? Give an estimate and explain it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0E12ifw6hOco"
      },
      "outputs": [],
      "source": [
        "# Your answer goes here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBMptXpzhOco"
      },
      "source": [
        "How big is the game tree that minimax search will go through? Give an estimate and explain it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2pZtVE7hOco"
      },
      "outputs": [],
      "source": [
        "# Your answer goes here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cueutrVYhOco"
      },
      "source": [
        "## Task 2: Game Environment and Random Agent [25 point]\n",
        "\n",
        "Use a numpy character array as the board."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gICGI8Z1hOcp",
        "outputId": "3764921d-f49c-4d69-c7f0-427fb356a688"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def empty_board(shape=(6, 7)):\n",
        "    return np.full(shape=shape, fill_value=0)\n",
        "\n",
        "print(empty_board())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5zXdGLRhOcp"
      },
      "source": [
        "The standard board is $6 \\times 7$ but you can use smaller boards to test your code. Instead of colors (red and yellow), I use 1 and -1 to represent the players. Make sure that your agent functions all have the from: `agent_type(board, player = 1)`, where board is the current board position (in the format above) and player is the player whose next move it is and who the agent should play (as 1 and -1)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "L4kThMuzhOcp",
        "outputId": "22a42cdb-cd8e-48c0-f15b-53de13e63a01"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Visualization code by Randolph Rankin\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize(board):\n",
        "    plt.axes()\n",
        "    rectangle=plt.Rectangle((-0.5,len(board)*-1+0.5),len(board[0]),len(board),fc='blue')\n",
        "    circles=[]\n",
        "    for i,row in enumerate(board):\n",
        "        for j,val in enumerate(row):\n",
        "            color='white' if val==0 else 'red' if val==1 else 'yellow'\n",
        "            circles.append(plt.Circle((j,i*-1),0.4,fc=color))\n",
        "\n",
        "    plt.gca().add_patch(rectangle)\n",
        "    for circle in circles:\n",
        "        plt.gca().add_patch(circle)\n",
        "\n",
        "    plt.axis('scaled')\n",
        "    plt.show()\n",
        "\n",
        "board = [[0, 0, 0, 0, 0, 0, 0],\n",
        "         [0, 0, 0, 0, 0, 0, 0],\n",
        "         [0, 0, 0, 0, 0, 0, 0],\n",
        "         [0, 0, 0, 1, 0, 0, 0],\n",
        "         [0, 0, 0, 1, 0, 0, 0],\n",
        "         [0,-1,-1, 1,-1, 0, 0]]\n",
        "visualize(board)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "o2W7pIiDhOcp"
      },
      "source": [
        "Implement helper functions for:\n",
        "\n",
        "* A check for available actions in each state `actions(state)`.\n",
        "* The transition model `result(state, player, action)`.\n",
        "* Check for terminal states `terminal(state)`.\n",
        "* The utility function `utility(state, player)`.\n",
        "\n",
        "The player argument is used so your agent can play red or yellow.\n",
        "Make sure that all these functions work with boards of different sizes (number of columns and rows).\n",
        "You can follow the [tic-tac-toe example from class.](https://colab.research.google.com/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_definitions.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 228,
      "metadata": {
        "id": "ep0HVJlChOcp"
      },
      "outputs": [],
      "source": [
        "# Your code/ answer goes here.\n",
        "# Your code/ answer goes here.\n",
        "\n",
        "def actions(state):\n",
        "  rows, cols = np.where(np.array(state)==0)\n",
        "  available_spaces = [(int(row), int(col)) for row, col in zip(rows, cols)]\n",
        "  available_moves = []\n",
        "\n",
        "  #highest row for each column\n",
        "  moves = {}\n",
        "  for i in range(len(state[0])):\n",
        "    moves[i] = 0\n",
        "  for i in range (len(available_spaces)):\n",
        "    if available_spaces[i][0] == 0 and moves[available_spaces[i][1]] == 0:\n",
        "      #del moves[available_spaces[i][1]]\n",
        "      continue\n",
        "    moves[available_spaces[i][1]] = max(available_spaces[i][0], moves[available_spaces[i][1]])\n",
        "  return moves\n",
        "\n",
        "def result(state, player, action):\n",
        "  if state[action[0]][action[1]] != 0:\n",
        "    raise ValueError(\"Invalid action\")\n",
        "  state = state.copy()\n",
        "  state[action[0]][action[1]] = player\n",
        "  return state\n",
        "\n",
        "def utility(state, player = -1):\n",
        "  goal = check_board(state)\n",
        "  if goal == 'd':\n",
        "    return 0\n",
        "  if goal == player:\n",
        "    return 1\n",
        "  if goal == other(player):\n",
        "    return -1\n",
        "  return None\n",
        "\n",
        "def terminal(state):\n",
        "    return check_board(state)!='n'\n",
        "\n",
        "def check_board(state):\n",
        "    \"\"\"check the board and return one of x, o, d (draw), or n (for next move)\"\"\"\n",
        "\n",
        "    state = np.array(state).reshape((6, 7))\n",
        "\n",
        "    def check_four(line):\n",
        "        \"\"\"Helper to check for 4 consecutive non-zero same values.\"\"\"\n",
        "        for i in range(len(line) - 3):\n",
        "            if line[i] != 0 and line[i] == line[i+1] == line[i+2] == line[i+3]:\n",
        "                return line[i]\n",
        "        return None\n",
        "\n",
        "    # Check horizontal\n",
        "    for row in state:\n",
        "        winner = check_four(row)\n",
        "        if winner:\n",
        "            return winner\n",
        "\n",
        "    # Check vertical\n",
        "    for col in state.T:\n",
        "        winner = check_four(col)\n",
        "        if winner:\n",
        "            return winner\n",
        "\n",
        "    # Check diagonals (bottom-left to top-right)\n",
        "    for i in range(-2, 4):  # diagonals that are at least length 4\n",
        "        diag = np.diagonal(state, offset=i)\n",
        "        winner = check_four(diag)\n",
        "        if winner:\n",
        "            return winner\n",
        "\n",
        "    # Check diagonals (top-left to bottom-right)\n",
        "    flipped = np.fliplr(state)\n",
        "    for i in range(-2, 4):\n",
        "        diag = np.diagonal(flipped, offset=i)\n",
        "        winner = check_four(diag)\n",
        "        if winner:\n",
        "            return winner\n",
        "\n",
        "    # Check for draw\n",
        "    if np.all(state != 0):\n",
        "        return 'd'\n",
        "\n",
        "    return 'n'\n",
        "\n",
        "def other(player):\n",
        "    if player == -1: return 1\n",
        "    else: return -1\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NLV-pd_hOcq"
      },
      "source": [
        "Implement an agent that plays randomly. Make sure the agent function receives as the percept the board and returns a valid action. Use an agent function definition with the following signature (arguments):\n",
        "\n",
        "`def random_player(board, player = 1): ...`\n",
        "\n",
        "The argument `player` is used for agents that do not store what color they are playing. The value passed on by the environment should be 1 ot -1 for player red and yellow, respectively.  See [Experiments section for tic-tac-toe](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_and_or_tree_search.ipynb#Experiments) for an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 224,
      "metadata": {
        "id": "6TOTqrtGhOcq"
      },
      "outputs": [],
      "source": [
        "# Your code/ answer goes here.\n",
        "import random\n",
        "def random_player(board, player = None):\n",
        "  key = random.choice(list(actions(board)))\n",
        "  while board[actions(board)[key]][key] != 0:\n",
        "    key = random.choice(list(actions(board)))\n",
        "  return (actions(board)[key],key)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AksWajvUhOcq"
      },
      "source": [
        "Let two random agents play against each other 1000 times. Look at the [Experiments section for tic-tac-toe](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_and_or_tree_search.ipynb#Experiments) to see how the environment uses the agent functions to play against each other.\n",
        "\n",
        "How often does each player win? Is the result expected?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRQZ3YO5hOcq",
        "outputId": "6c146434-a15b-48fc-d6fa-5f6ede235b19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0]]\n",
            "[[ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0 -1  0  0  0  0  0]]\n",
            "[[ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  1  0  0  0  0  0]\n",
            " [ 0 -1  0  0  0  0  0]]\n",
            "[[ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  1  0  0  0  0  0]\n",
            " [ 0 -1  0  0  0 -1  0]]\n",
            "[[ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  1  0  0  0  0  0]\n",
            " [ 0  1  0  0  0  0  0]\n",
            " [ 0 -1  0  0  0 -1  0]]\n",
            "[[ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  1  0  0  0  0  0]\n",
            " [ 0  1  0  0  0  0  0]\n",
            " [ 0 -1  0  0  0 -1 -1]]\n",
            "[[ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  1  0  0  0  0  0]\n",
            " [ 0  1  0  0  0  0  0]\n",
            " [ 0 -1  0  0  1 -1 -1]]\n",
            "[[ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  1  0  0  0  0  0]\n",
            " [ 0  1  0  0  0  0 -1]\n",
            " [ 0 -1  0  0  1 -1 -1]]\n",
            "[[ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  1  0  0  0  0  0]\n",
            " [ 0  1  0  0  0  0  0]\n",
            " [ 0  1  0  0  0  0 -1]\n",
            " [ 0 -1  0  0  1 -1 -1]]\n",
            "[[ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  1  0  0  0  0  0]\n",
            " [ 0  1  0  0  0  0  0]\n",
            " [ 0  1  0  0  0  0 -1]\n",
            " [ 0 -1 -1  0  1 -1 -1]]\n",
            "[[ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  1  0  0  0  0  0]\n",
            " [ 0  1  0  0  0  0  0]\n",
            " [ 0  1  0  0  0  1 -1]\n",
            " [ 0 -1 -1  0  1 -1 -1]]\n",
            "[[ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  1  0  0  0  0  0]\n",
            " [ 0  1  0  0  0  0  0]\n",
            " [ 0  1  0  0  0  1 -1]\n",
            " [-1 -1 -1  0  1 -1 -1]]\n",
            "[[ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  1  0  0  0  0  0]\n",
            " [ 0  1  0  0  0  0  0]\n",
            " [ 0  1  1  0  0  1 -1]\n",
            " [-1 -1 -1  0  1 -1 -1]]\n",
            "[[ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  1  0  0  0  0  0]\n",
            " [ 0  1  0  0  0  0  0]\n",
            " [ 0  1  1  0  0  1 -1]\n",
            " [-1 -1 -1 -1  1 -1 -1]]\n",
            "{-1: 0, 1: 0, 'd': 0}\n",
            "[[ 0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0]\n",
            " [ 0  1  0  0  0  0  0]\n",
            " [ 0  1  0  0  0  0  0]\n",
            " [ 0  1  1  0  0  1 -1]\n",
            " [-1 -1 -1 -1  1 -1 -1]]\n",
            "{-1: 1, 1: 0, 'd': 0}\n"
          ]
        }
      ],
      "source": [
        "# Your code/ answer goes here.\n",
        "def play(player1=1,player2=-1,N=1,show_final_board = False):\n",
        "  results = {-1:0,1:0,'d':0}\n",
        "  for i in range(N):\n",
        "    board = empty_board()\n",
        "    while True:\n",
        "      print(board)\n",
        "      a = random_player(board,-1)\n",
        "      board = result(board,-1,a)\n",
        "      print(board)\n",
        "      win = check_board(board)\n",
        "      if win!='n':\n",
        "        print(results)\n",
        "        print(board)\n",
        "        results[win]+=1\n",
        "        break\n",
        "      b = random_player(board,1)\n",
        "      board = result(board,1,b)\n",
        "      win = check_board(board)\n",
        "      if win!='n':\n",
        "        print(results)\n",
        "        print(board)\n",
        "        results[win]+=1\n",
        "        break\n",
        "    if show_final_board:\n",
        "     visualize(board)\n",
        "  return results\n",
        "\n",
        "print(play())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqoZg7kdhOcq"
      },
      "source": [
        "## Task 3: Minimax Search with Alpha-Beta Pruning\n",
        "\n",
        "### Implement the Search [20 points]\n",
        "\n",
        "Implement minimax search starting from a given board for specifying the player.\n",
        "\n",
        "__Important Notes:__\n",
        "* You can use code from the [tic-tac-toe example](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_alpha_beta_tree_search.ipynb).\n",
        "* Make sure that all your agent functions have a signature consistent with the random agent above and that it [uses a class to store state information.](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/HOWTOs/store_agent_state_information.ipynb)\n",
        "This is essential to be able play against agents from other students later.\n",
        "* The game tree for a $6 \\times 7$ board is huge and optimal algorithms need to visit each or a large percentage of all nodes in the tree. You can experiment with smaller boards like a $4 \\times 4$ board first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 260,
      "metadata": {
        "id": "pHlHV1XjhOcq"
      },
      "outputs": [],
      "source": [
        "# Your code/ answer goes here.\n",
        "\n",
        "def minimax_search(game, state):\n",
        "  player = game.result(state, game.player, actions(state))\n",
        "  value, move = max_value(game, state)\n",
        "  return move\n",
        "\n",
        "def max_value(game, state):\n",
        "  if terminal(state):\n",
        "    return utility(state)\n",
        "  v = -np.inf\n",
        "  for action in actions(state):\n",
        "    v2,a2 = min_value(game, result(state, game.player, action))\n",
        "    if v2 > v:\n",
        "      v,move = v2,action\n",
        "  return v,move\n",
        "\n",
        "def min_value(game, state):\n",
        "  if game.terminal(state):\n",
        "    return utility(state),null\n",
        "  v = np.inf\n",
        "  for action in actions(state):\n",
        "    v2,a2 = max_value(game, result(state, game.player, action))\n",
        "    if v2 < v:\n",
        "      v,move = v2,action\n",
        "  return v,move"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIFOj-ClhOcq"
      },
      "source": [
        "Experiment with some manually created boards (at least 5) to check if the agent spots winning opportunities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjMM83kjhOcq"
      },
      "outputs": [],
      "source": [
        "# Your code/ answer goes here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtJdjpgWhOcq"
      },
      "source": [
        "How long does it take to make a move? Start with a smaller board with 4 columns and make the board larger by adding columns/rows. Explain why using this algorithm on a standard $6 \\times 7$ board takes forever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sV2CQHRphOcq"
      },
      "outputs": [],
      "source": [
        "# Your code/ answer goes here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zc3n96sMhOcq"
      },
      "source": [
        "### Move ordering [5 points]\n",
        "\n",
        "Starting the search with better moves will increase the efficiency of alpha-beta pruning. Describe and implement a simple move ordering strategy. Make a table that shows how the ordering strategies influence the time it takes to make a move?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sm0DLmeRhOcq"
      },
      "outputs": [],
      "source": [
        "# Your code/ answer goes here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsPxErrJhOcq"
      },
      "source": [
        "### The first few moves [5 points]\n",
        "\n",
        "Start with an empty board. This is the worst case scenario for minimax search since it needs solve all possible games that can be played (minus some pruning) before making the decision. What can you do?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvfyEjGBhOcq"
      },
      "outputs": [],
      "source": [
        "# Your code/ answer goes here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQ5_IIoKhOcq"
      },
      "source": [
        "### Playtime [5 points]\n",
        "\n",
        "Let the Minimax Search agent play a random agent on a $4 \\times 4$ board. Analyze wins, losses and draws."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3UEXGsfhOcr"
      },
      "outputs": [],
      "source": [
        "# Your code/ answer goes here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uY4qKn4phOcr"
      },
      "source": [
        "## Task 4: Heuristic Alpha-Beta Tree Search\n",
        "\n",
        "### Heuristic evaluation function [15 points]\n",
        "\n",
        "Define and implement a heuristic evaluation function. Make sure that the heuristic value stays in the correct range."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5KCucDGqhOcr"
      },
      "outputs": [],
      "source": [
        "# Your code/ answer goes here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IWGkr9DhOcr"
      },
      "source": [
        "### Cutting Off Search [10 points]\n",
        "\n",
        "Modify your minimax search with alpha-beta pruning to cut off search at a specified depth and use the heuristic evaluation function. Experiment with different cutoff values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFjlr72ThOcr"
      },
      "outputs": [],
      "source": [
        "# Your code/ answer goes here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKJssOUKhOcr"
      },
      "source": [
        "Experiment with the same manually created boards as above to check if the agent spots wining opportunities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLJyTY8YhOcr"
      },
      "outputs": [],
      "source": [
        "# Your code/ answer goes here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsKtOOBnhOcr"
      },
      "source": [
        "How long does it take to make a move? Start with a smaller board with 4 columns and make the board larger by adding columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_7t0JQ0MhOcr"
      },
      "outputs": [],
      "source": [
        "# Your code/ answer goes here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSWu2dkOhOcr"
      },
      "source": [
        "### Playtime [5 points]\n",
        "\n",
        "Let two heuristic search agents (different cutoff depth, different heuristic evaluation function) compete against each other on a reasonably sized board. Since there is no randomness, you only need to let them play once."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOub8qxihOcr"
      },
      "outputs": [],
      "source": [
        "# Your code/ answer goes here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMHFyR_hhOcu"
      },
      "source": [
        "## Challenge task [up to +10 bonus point will be awarded separately]\n",
        "\n",
        "Find another student and let your best agent play against the other student's best player. We will set up a class tournament on Canvas. This tournament will continue after the submission deadline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMXWu5xKhOcv"
      },
      "source": [
        "## Graduate student advanced task: Pure Monte Carlo Search and Best First Move [10 point]\n",
        "\n",
        "__Undergraduate students:__ This is a bonus task you can attempt if you like [+5 bonus point].\n",
        "\n",
        "### Pure Monte Carlo Search\n",
        "\n",
        "Implement Pure Monte Carlo Search and investigate how this search performs on the test boards that you have used above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "metadata": {
        "id": "pLqNjv0rhOcv"
      },
      "outputs": [],
      "source": [
        "# Your code/ answer goes here.\n",
        "def monte_carlo_search(state):\n",
        "  tree = node(state)\n",
        "  while is_timing_remaining():\n",
        "    leaf = select(tree)\n",
        "    child = expand(leaf)\n",
        "    result = simulate(child)\n",
        "    backpropagate(result)\n",
        "  return max(tree.children, key=lambda c: c.wins/c.visits)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFIQdYDGhOcv"
      },
      "source": [
        "### Best First Move\n",
        "\n",
        "Use your Monte Carlo Search to determine what the best first move for red is? Describe under what assumptions this is the \"best\" first move.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNHyr7yKhOcv"
      },
      "outputs": [],
      "source": [
        "# Your code/ answer goes here."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}